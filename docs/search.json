[
  {
    "objectID": "Modeling File.html",
    "href": "Modeling File.html",
    "title": "Modeling File",
    "section": "",
    "text": "The test-train data is 70%-30%, hence we have to set our prop to “0.70”.\n\n#set.seed(11)\n#diabetes_split &lt;- initial_split(diabetes_health_indicators, prop = 0.70)\n#diabetes_train &lt;- training(diabetes_split)\n#diabetes_test &lt;- testing(diabetes_split)\n#diabetes_10_fold &lt;- vfold_cv(diabetes_train, 10)\n\nClassification Tree\nAs discussed in the notes, the 5-fold cross-validation algorithm is a method for fitting and evaluating a model. As its name implies the 5-fold cross-validation splits the training data into 5 equal parts (also called “folds”).\n\n#LASSO_grid |&gt;\n#collect_metrics() |&gt;\n#filter(.metric == \"rmse\") |&gt;\n#ggplot(aes(penalty, mean, color = .metric)) +\n#geom_line()\n\n\n#lowest_rmse &lt;- LASSO_grid |&gt;\n#select_best(metric = \"rmse\")\n#lowest_rmse\n\nRandom Forest Tree\nAccording to the lectures, a “random forest” is a type of model, that is produced by generating “single” trees on models of data, as well as a subset of predictors (that is randomly selected) for each tree-splitting step. The predictors from each of the “single” trees are then combined to create the overall prediction.\n\n#rf_spec &lt;- rand_forest(mtry = tune()) |&gt;\n#set_engine(\"ranger\",importance = \"impurity\") |&gt;\n#set_mode(\"regression\")\n\n\n#rf_wkf &lt;- workflow() |&gt;\n#add_recipe(MLR_rec1) |&gt;\n#add_model(rf_spec)\n\n\n#rf_fit &lt;- rf_wkf |&gt;\n#tune_grid(resamples = bike_10_fold,\n#grid = 12)\n\n\n#rf_fit |&gt;\n#collect_metrics() |&gt;\n#filter(.metric == \"rmse\") |&gt;\n#arrange(mean)\n\n\n#rf_fit |&gt;\n#collect_metrics() |&gt;\n#filter(.metric == \"rmse\") |&gt;\n#arrange(mean)\n\n\n#final_fit &lt;- workflow() |&gt;\n#add_recipe(MLR_rec1) |&gt;\n#add_model(MLR_spec) |&gt;\n#last_fit(diabetes_split, metrics = metric_set(rmse, mae))\n#final_fit |&gt;\n#collect_metrics()\n\n\n#workflow() |&gt;\n#add_recipe(MLR_rec1) |&gt;\n#add_model(MLR_spec) |&gt;\n#fit(diabetes_train) |&gt;\n#tidy()"
  },
  {
    "objectID": "Modeling File.html#modeling-file",
    "href": "Modeling File.html#modeling-file",
    "title": "Modeling File",
    "section": "",
    "text": "The test-train data is 70%-30%, hence we have to set our prop to “0.70”.\n\n#set.seed(11)\n#diabetes_split &lt;- initial_split(diabetes_health_indicators, prop = 0.70)\n#diabetes_train &lt;- training(diabetes_split)\n#diabetes_test &lt;- testing(diabetes_split)\n#diabetes_10_fold &lt;- vfold_cv(diabetes_train, 10)\n\nClassification Tree\nAs discussed in the notes, the 5-fold cross-validation algorithm is a method for fitting and evaluating a model. As its name implies the 5-fold cross-validation splits the training data into 5 equal parts (also called “folds”).\n\n#LASSO_grid |&gt;\n#collect_metrics() |&gt;\n#filter(.metric == \"rmse\") |&gt;\n#ggplot(aes(penalty, mean, color = .metric)) +\n#geom_line()\n\n\n#lowest_rmse &lt;- LASSO_grid |&gt;\n#select_best(metric = \"rmse\")\n#lowest_rmse\n\nRandom Forest Tree\nAccording to the lectures, a “random forest” is a type of model, that is produced by generating “single” trees on models of data, as well as a subset of predictors (that is randomly selected) for each tree-splitting step. The predictors from each of the “single” trees are then combined to create the overall prediction.\n\n#rf_spec &lt;- rand_forest(mtry = tune()) |&gt;\n#set_engine(\"ranger\",importance = \"impurity\") |&gt;\n#set_mode(\"regression\")\n\n\n#rf_wkf &lt;- workflow() |&gt;\n#add_recipe(MLR_rec1) |&gt;\n#add_model(rf_spec)\n\n\n#rf_fit &lt;- rf_wkf |&gt;\n#tune_grid(resamples = bike_10_fold,\n#grid = 12)\n\n\n#rf_fit |&gt;\n#collect_metrics() |&gt;\n#filter(.metric == \"rmse\") |&gt;\n#arrange(mean)\n\n\n#rf_fit |&gt;\n#collect_metrics() |&gt;\n#filter(.metric == \"rmse\") |&gt;\n#arrange(mean)\n\n\n#final_fit &lt;- workflow() |&gt;\n#add_recipe(MLR_rec1) |&gt;\n#add_model(MLR_spec) |&gt;\n#last_fit(diabetes_split, metrics = metric_set(rmse, mae))\n#final_fit |&gt;\n#collect_metrics()\n\n\n#workflow() |&gt;\n#add_recipe(MLR_rec1) |&gt;\n#add_model(MLR_spec) |&gt;\n#fit(diabetes_train) |&gt;\n#tidy()"
  },
  {
    "objectID": "Exploratory Data Analysis (EDA).html",
    "href": "Exploratory Data Analysis (EDA).html",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Exploratory Data Analysis\nAs stated per the notes, Exploratory Data Analysis consists of a few steps:\n\nUnderstanding and analyzing how the data is stored\nDo basic data validation\nDetermine how many missing values are there for each variable (check for missing values)\nClean up data when necessary\nInvestigate the distributions of the data\nThen, apply the data transformations to the original data\n\nData Structure\nThrough the str() command, we will check the structure of the data. str() stands for structure.\n\n#str(diabetes_health_indicators)\n\nBasic Data Validation\nIn order to perform the process of basic data validation, we could use the psych::describe() for a dataset. The “psych” package is an R package which contains various functions used for data analysis; and contains tools for data visualization, factor analysis, reliability analysis, correlation analysis, and more.\n\n#psych::describe(diabetes_health_indicators)\n\nDetermining the Rate of Missing Values\n\n#colSums(is.na(diabetes_health_indicators))\n\nDetermine Rate of Missing Values\n\n#sum_na &lt;- function(column){\n #sum(is.na(column))\n#}\n#na_counts &lt;- diabetes_health_indicators |&gt;\n #summarize(across(everything(), sum_na))\n#na_counts\n\nClean Up Data as Needed\n\n#diabetes_health_indicators |&gt;\n #drop_na(names(diabetes_health_indicators)[na_counts &lt; 30])\n\nImputing Values\n\n#diabetes_health_indicators &lt;- diabetes_health_indicators |&gt;\n #replace_na(list(BMI = mean(diabetes_health_indicators$BMI, na.rm = TRUE),\n #Height = mean(diabetes_health_indicators$Height, na.rm = TRUE)))\n#diabetes_health_indicators\n\nLet’s create factor versions of our three variables.\n\n#unique(diabetes_health_indicators$Sex)\n\nContingency Tables\n\n#diabetes_health_indicators |&gt;\n #group_by(Sex) |&gt;\n #drop_na(Sex) |&gt;\n #summarize(count = n())"
  }
]